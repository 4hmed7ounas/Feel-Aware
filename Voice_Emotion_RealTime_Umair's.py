import os
import time
import sounddevice as sd
from scipy.io.wavfile import write
from speechbrain.inference.interfaces import foreign_class
import threading
import keyboard  # pip install keyboard

# ğŸ§  Load the custom classifier
classifier = foreign_class(
    source="speechbrain/emotion-recognition-wav2vec2-IEMOCAP",
    pymodule_file="custom_interface.py",
    classname="CustomEncoderWav2vec2Classifier"
)

# ğŸ§ Settings
FILENAME = "recording.wav"
DURATION = 3  # seconds
FS = 16000  # sample rate

# ğŸ™ï¸ Record audio
def record_audio(filename=FILENAME, duration=DURATION, fs=FS):
    print("\033[94mğŸ™ï¸  Listening... ({} sec)\033[0m".format(duration))
    audio = sd.rec(int(duration * fs), samplerate=fs, channels=1)
    sd.wait()
    write(filename, fs, audio)

# ğŸ” Predict emotion
def predict_emotion(filename=FILENAME):
    out_prob, score, index, text_lab = classifier.classify_file(filename)
    print(f"\033[92mğŸ§  Emotion: {text_lab} | ğŸ“Š Score: {score}\033[0m\n")

# ğŸ” Main loop
def main_loop():
    print("\033[96mğŸ”„ Starting real-time emotion detection (Press 'X' to stop)\033[0m\n")
    while not keyboard.is_pressed('x'):
        record_audio()
        predict_emotion()
    print("\n\033[91mğŸ›‘ Detection stopped by user.\033[0m")

# ğŸš€ Entry point
if __name__ == "__main__":
    try:
        main_loop()
    except KeyboardInterrupt:
        print("\n\033[91mâ›” Interrupted manually.\033[0m")
    finally:
        if os.path.exists(FILENAME):
            os.remove(FILENAME)
